{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head-to-head comparison of R, Python, Julia, and C/C++\n",
    "\n",
    "System information (for reproducibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.7.3\n",
      "Commit 742b9abb4d (2022-05-06 12:58 UTC)\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin21.4.0)\n",
      "  CPU: Intel(R) Core(TM) i7-6920HQ CPU @ 2.90GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-12.0.1 (ORCJIT, skylake)\n",
      "Environment:\n",
      "  JULIA_EDITOR = code\n",
      "  JULIA_NUM_THREADS = 4\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Documents/github.com/JSM-Julia-Short-Course-2022/Docker`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m      Status\u001b[22m\u001b[39m `~/Documents/github.com/JSM-Julia-Short-Course-2022/Docker/Project.toml`\n",
      " \u001b[90m [1520ce14] \u001b[39mAbstractTrees v0.3.4\n",
      " \u001b[90m [336ed68f] \u001b[39mCSV v0.10.4\n",
      " \u001b[90m [31c24e10] \u001b[39mDistributions v0.25.66\n",
      " \u001b[90m [38e38edf] \u001b[39mGLM v1.8.0\n",
      " \u001b[90m [28b8d3ca] \u001b[39mGR v0.66.0\n",
      " \u001b[90m [c27321d9] \u001b[39mGlob v1.3.0\n",
      " \u001b[90m [a15396b6] \u001b[39mOnlineStats v1.5.13\n",
      " \u001b[90m [ca7969ec] \u001b[39mPlotlyLight v0.5.1\n",
      " \u001b[90m [91a5bcdd] \u001b[39mPlots v1.31.5\n",
      " \u001b[90m [c3e4b0f8] \u001b[39mPluto v0.19.11\n",
      " \u001b[90m [7f904dfe] \u001b[39mPlutoUI v0.7.39\n",
      " \u001b[90m [438e738f] \u001b[39mPyCall v1.93.1\n",
      " \u001b[90m [6f49c342] \u001b[39mRCall v0.13.13\n",
      " \u001b[90m [ce6b1742] \u001b[39mRDatasets v0.7.7\n",
      " \u001b[90m [2913bbd2] \u001b[39mStatsBase v0.33.20\n",
      " \u001b[90m [f3b207a7] \u001b[39mStatsPlots v0.15.1\n",
      " \u001b[90m [b8865327] \u001b[39mUnicodePlots v3.0.4\n"
     ]
    }
   ],
   "source": [
    "# load packages in environment\n",
    "import Pkg\n",
    "Pkg.activate(\"../../Docker\")\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of computer languages\n",
    "\n",
    "* **Compiled languages** (low-level languages): C/C++, Fortran, ... \n",
    "  - Directly compiled to machine code that is executed by CPU \n",
    "  - Pros: fast, memory efficient\n",
    "  - Cons: longer development time, hard to debug\n",
    "\n",
    "* **Interpreted language** (high-level languages): R, Matlab, Python, SAS IML, JavaScript, ... \n",
    "  - Interpreted by interpreter\n",
    "  - Pros: fast prototyping\n",
    "  - Cons: excruciatingly slow for loops\n",
    "\n",
    "* Mixed (dynamic) languages: Matlab (JIT), R (`compiler` package), Julia, Cython, JAVA, ...\n",
    "  - Pros and cons: between the compiled and interpreted languages\n",
    "\n",
    "* Script languages: Linux shell scripts, Perl, ...\n",
    "  - Extremely useful for some data preprocessing and manipulation\n",
    "\n",
    "* Database languages: SQL, Hive (Hadoop).  \n",
    "  - Data analysis *never* happens if we do not know how to retrieve data from databases  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How high-level languages work?\n",
    "\n",
    "- Typical execution of a high-level language such as R, Python, and Matlab.\n",
    "\n",
    "<img src=\"./r-bytecode.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "- To improve efficiency of interpreted languages such as R, Matlab and Python, conventional wisdom is to avoid loops as much as possible. Aka, **vectorize code**\n",
    "> The only loop you are allowed to have is that for an iterative algorithm.\n",
    "\n",
    "- When looping is unavoidable, need to code in C, C++, or Fortran. This creates the notorious **two language problem**  \n",
    "Success stories: the popular `glmnet` package in R is coded in Fortran; `tidyverse` and `data.table` packages use a lot RCpp/C++.\n",
    "\n",
    "<img src=\"./two_language_problem.jpg\" align=\"center\" width=\"600\"/>\n",
    "\n",
    "- High-level languages have made many efforts to bring themselves closer to the performance of low-level languages such as C, C++, or Fortran, with a variety levels of success.   \n",
    "    - Matlab has employed JIT (just-in-time compilation) technology since 2002.  \n",
    "    - Since R 3.4.0 (Apr 2017), the JIT bytecode compiler is enabled by default at its level 3.   \n",
    "    - Cython is a compiler system based on Python.  \n",
    "\n",
    "- Modern languages such as Julia tries to solve the two language problem. That is to achieve efficiency without vectorizing code.\n",
    "\n",
    "- Julia execution.\n",
    "\n",
    "<img src=\"./julia_compile.png\" align=\"center\" width=\"400\"/>\n",
    "\n",
    "<img src=\"./julia_introspect.png\" align=\"center\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gibbs sampler example by Doug Bates\n",
    "\n",
    "- Doug Bates (member of R-Core, author of popular R packages `Matrix`, `lme4`, `RcppEigen`, etc)\n",
    "    \n",
    "    > As some of you may know, I have had a (rather late) mid-life crisis and run off with another language called Julia.   \n",
    "    >\n",
    "    > -- <cite>Doug Bates (on the `knitr` Google Group)</cite>\n",
    "\n",
    "- An example from Dr. Doug Bates's slides [Julia for R Programmers](http://www.stat.wisc.edu/~bates/JuliaForRProgrammers.pdf).\n",
    "\n",
    "- The task is to create a Gibbs sampler for the density  \n",
    "$$\n",
    "f(x, y) = k x^2 exp(- x y^2 - y^2 + 2y - 4x), x > 0\n",
    "$$\n",
    "using the conditional distributions\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "  X | Y &\\sim& \\Gamma \\left( 3, \\frac{1}{y^2 + 4} \\right) \\\\\n",
    "  Y | X &\\sim& N \\left(\\frac{1}{1+x}, \\frac{1}{2(1+x)} \\right).\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* R solution. The `RCall.jl` package allows us to execute R code without leaving the `Julia` environment. We first define an R function `Rgibbs()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "R version 4.1.2 (2021-11-01)\n",
       "Platform: x86_64-apple-darwin17.0 (64-bit)\n",
       "Running under: macOS Big Sur 10.16\n",
       "\n",
       "Matrix products: default\n",
       "BLAS:   /Applications/Julia-1.7.app/Contents/Resources/julia/lib/julia/libblastrampoline.dylib\n",
       "LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib\n",
       "\n",
       "locale:\n",
       "[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n",
       "\n",
       "attached base packages:\n",
       "[1] stats     graphics  grDevices utils     datasets  methods   base     \n",
       "\n",
       "loaded via a namespace (and not attached):\n",
       "[1] compiler_4.1.2\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "# show R information\n",
    "R\"\"\"\n",
    "sessionInfo()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{ClosSxp}\n",
       "function (N, thin) \n",
       "{\n",
       "    mat <- matrix(0, nrow = N, ncol = 2)\n",
       "    x <- y <- 0\n",
       "    for (i in 1:N) {\n",
       "        for (j in 1:thin) {\n",
       "            x <- rgamma(1, 3, y * y + 4)\n",
       "            y <- rnorm(1, 1/(x + 1), 1/sqrt(2 * (x + 1)))\n",
       "        }\n",
       "        mat[i, ] <- c(x, y)\n",
       "    }\n",
       "    mat\n",
       "}\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function for Gibbs sampling\n",
    "\n",
    "R\"\"\"\n",
    "library(Matrix)\n",
    "\n",
    "Rgibbs <- function(N, thin) {\n",
    "  mat <- matrix(0, nrow=N, ncol=2)\n",
    "  x <- y <- 0\n",
    "  for (i in 1:N) {\n",
    "    for (j in 1:thin) {\n",
    "      x <- rgamma(1, 3, y * y + 4) # 3rd arg is rate\n",
    "      y <- rnorm(1, 1 / (x + 1), 1 / sqrt(2 * (x + 1)))\n",
    "    }\n",
    "    mat[i,] <- c(x, y)\n",
    "  }\n",
    "  mat\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a sample of size 10,000 with a thinning of 500. How long does it take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{RealSxp}\n",
       "   user  system elapsed \n",
       " 22.740   1.751  24.717 \n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "system.time(Rgibbs(10000, 500))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This is a Julia function for the same Gibbs sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jgibbs (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "\n",
    "function jgibbs(N, thin)\n",
    "    mat = zeros(N, 2)\n",
    "    x = y = 0.0\n",
    "    for i in 1:N\n",
    "        for j in 1:thin\n",
    "            x = rand(Gamma(3, 1 / (y * y + 4)))\n",
    "            y = rand(Normal(1 / (x + 1), 1 / sqrt(2(x + 1))))\n",
    "        end\n",
    "        mat[i, 1] = x\n",
    "        mat[i, 2] = y\n",
    "    end\n",
    "    mat\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the same number of samples. How long does it take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.279728267"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jgibbs(100, 5); # warm-up\n",
    "@elapsed jgibbs(10000, 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see 40-80 fold speed up of `Julia` over `R` on this example, **with similar coding effort**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing C, R, Python, and Julia\n",
    "\n",
    "To better understand how these languages work, we consider a simple task: summing a vector.\n",
    "\n",
    "Let's first generate data: 1 million double precision numbers from uniform [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500220.6882968192"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random # standard library\n",
    "Random.seed!(123) # seed\n",
    "x = rand(1_000_000) # 1 million random numbers in [0, 1)\n",
    "sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class, we use package `BenchmarkTools.jl` for robust benchmarking. It's analog of `microbenchmark` or `bench` package in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C\n",
    "\n",
    "We would use the low-level C code as the baseline for copmarison. In Julia, we can easily run compiled C code using the `ccall` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c_sum (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Libdl\n",
    "\n",
    "C_code = \"\"\"\n",
    "#include <stddef.h>\n",
    "double c_sum(size_t n, double *X) {\n",
    "    double s = 0.0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        s += X[i];\n",
    "    }\n",
    "    return s;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "const Clib = tempname()   # make a temporary file\n",
    "\n",
    "# compile to a shared library by piping C_code to gcc\n",
    "# (works only if you have gcc installed):\n",
    "\n",
    "open(`gcc -std=c99 -fPIC -O3 -msse3 -xc -shared -o $(Clib * \".\" * Libdl.dlext) -`, \"w\") do f\n",
    "    print(f, C_code) \n",
    "end\n",
    "\n",
    "# define a Julia function that calls the C function:\n",
    "c_sum(X::Array{Float64}) = ccall((\"c_sum\", Clib), Float64, (Csize_t, Ptr{Float64}), length(X), X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500220.6882968189"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure it gives same answer\n",
    "c_sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 4238 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.124 ms\u001b[22m\u001b[39m … \u001b[35m 1.761 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.161 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.176 ms\u001b[22m\u001b[39m ± \u001b[32m63.037 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m█\u001b[39m▆\u001b[39m \u001b[39m \u001b[39m \u001b[34m▁\u001b[39m\u001b[39m▂\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▄\u001b[39m▄\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m▅\u001b[39m\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m▃\n",
       "  1.12 ms\u001b[90m        Histogram: frequency by time\u001b[39m        1.46 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm = @benchmark c_sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1608855"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics # standard library\n",
    "benchmark_result = Dict() # a dictionary to store median runtime (in milliseconds)\n",
    "\n",
    "# store median runtime (in milliseconds)\n",
    "benchmark_result[\"C\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R, buildin sum\n",
    "\n",
    "Next we compare to the build in `sum` function in R, which is implemented using C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "# A tibble: 1 × 13\n",
       "  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n",
       "  <bch:expr> <bch:tm> <bch:>     <dbl> <bch:byt>    <dbl> <int> <dbl>   <bch:tm>\n",
       "1 sum(y)       2.38ms 2.46ms      402.        0B        0   202     0      503ms\n",
       "# … with 4 more variables: result <list>, memory <list>, time <list>, gc <list>\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "library(bench)\n",
    "y <- $x\n",
    "rbm_builtin <- bench::mark(sum(y))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4625275000014213"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "@rget rbm_builtin # dataframe\n",
    "benchmark_result[\"R builtin\"] = median(rbm_builtin[!, :median]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R, handwritten loop\n",
    "\n",
    "Handwritten loop in R is much slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "# A tibble: 1 × 13\n",
       "  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n",
       "  <bch:expr> <bch:tm> <bch:>     <dbl> <bch:byt>    <dbl> <int> <dbl>   <bch:tm>\n",
       "1 sum_r(y)     12.7ms   13ms      76.1    12.7KB        0    39     0      513ms\n",
       "# … with 4 more variables: result <list>, memory <list>, time <list>, gc <list>\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using RCall\n",
    "\n",
    "R\"\"\"\n",
    "sum_r <- function(x) {\n",
    "  s <- 0\n",
    "  for (xi in x) {\n",
    "    s <- s + xi\n",
    "  }\n",
    "  s\n",
    "}\n",
    "library(bench)\n",
    "y <- $x\n",
    "rbm_loop <- bench::mark(sum_r(y))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.011620000000335"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "@rget rbm_loop # dataframe\n",
    "benchmark_result[\"R loop\"] = median(rbm_loop[!, :median]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R, Rcpp\n",
    "\n",
    "Rcpp package is the easiest way to incorporate C++ code in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{ClosSxp}\n",
       "function (x) \n",
       ".Call(<pointer: 0x11042c850>, x)\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "library(Rcpp)\n",
    "\n",
    "cppFunction('double rcpp_sum(NumericVector x) {\n",
    "  int n = x.size();\n",
    "  double total = 0;\n",
    "  for(int i = 0; i < n; ++i) {\n",
    "    total += x[i];\n",
    "  }\n",
    "  return total;\n",
    "}')\n",
    "rcpp_sum\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RObject{VecSxp}\n",
       "# A tibble: 1 × 13\n",
       "  expression      min median `itr/sec` mem_alloc `gc/sec` n_itr  n_gc total_time\n",
       "  <bch:expr>  <bch:t> <bch:>     <dbl> <bch:byt>    <dbl> <int> <dbl>   <bch:tm>\n",
       "1 rcpp_sum(y)  1.17ms 1.21ms      814.    2.49KB        0   407     0      500ms\n",
       "# … with 4 more variables: result <list>, memory <list>, time <list>, gc <list>\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R\"\"\"\n",
    "rbm_rcpp <- bench::mark(rcpp_sum(y))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2082829999986444"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in milliseconds)\n",
    "@rget rbm_rcpp # dataframe\n",
    "benchmark_result[\"R Rcpp\"] = median(rbm_rcpp[!, :median]) * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, builtin sum\n",
    "\n",
    "Built in function `sum` in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"3.7.6\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "PyCall.pyversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 67 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m71.462 ms\u001b[22m\u001b[39m … \u001b[35m99.945 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m74.757 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m75.408 ms\u001b[22m\u001b[39m ± \u001b[32m 3.503 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▄\u001b[39m█\u001b[39m▂\u001b[39m▄\u001b[39m▂\u001b[39m \u001b[39m \u001b[34m \u001b[39m\u001b[39m▂\u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▄\u001b[39m█\u001b[34m▆\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m▆\u001b[39m\u001b[39m▄\u001b[39m█\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m▆\u001b[39m▄\u001b[39m▁\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m \u001b[39m▁\n",
       "  71.5 ms\u001b[90m         Histogram: frequency by time\u001b[39m        81.7 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m240 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the Python built-in \"sum\" function:\n",
    "pysum = pybuiltin(\"sum\")\n",
    "bm = @benchmark $pysum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.757128"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python builtin\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, handwritten loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 53 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m93.538 ms\u001b[22m\u001b[39m … \u001b[35m104.348 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m95.496 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m95.787 ms\u001b[22m\u001b[39m ± \u001b[32m  2.257 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m█\u001b[39m▅\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[34m▂\u001b[39m\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m▅\u001b[39m \u001b[39m \u001b[39m▅\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m█\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▁\u001b[34m█\u001b[39m\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▅\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m \u001b[39m▁\n",
       "  93.5 ms\u001b[90m         Histogram: frequency by time\u001b[39m          102 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m240 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using PyCall\n",
    "\n",
    "py\"\"\"\n",
    "def py_sum(A):\n",
    "    s = 0.0\n",
    "    for a in A:\n",
    "        s += a\n",
    "    return s\n",
    "\"\"\"\n",
    "\n",
    "sum_py = py\"py_sum\"\n",
    "\n",
    "bm = @benchmark $sum_py($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.496408"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python loop\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python, numpy\n",
    "\n",
    "Numpy is the high-performance scientific computing library for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyObject <function sum at 0x7fc410068b90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bring in sum function from Numpy \n",
    "numpy_sum = pyimport(\"numpy\").\"sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m378.482 μs\u001b[22m\u001b[39m … \u001b[35m 1.160 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m412.020 μs              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m434.387 μs\u001b[22m\u001b[39m ± \u001b[32m64.678 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[34m▆\u001b[39m\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[32m▅\u001b[39m\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\n",
       "  \u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m▅\u001b[39m▇\u001b[39m▅\u001b[39m▆\u001b[39m▇\u001b[39m▅\u001b[39m▆\u001b[39m▇\u001b[39m▅\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▅\u001b[39m▄\u001b[39m \u001b[39m█\n",
       "  378 μs\u001b[90m        \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m       726 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m240 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m6\u001b[39m."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm = @benchmark $numpy_sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41202"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store median runtime (in miliseconds)\n",
    "benchmark_result[\"Python numpy\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy performance is on a par with Julia build-in sum function. Both are about 3 times faster than C, possibly because of usage of [SIMD](https://en.wikipedia.org/wiki/SIMD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Julia, builtin sum\n",
    "\n",
    "`@time`, `@elapsed`, `@allocated` macros in Julia report run times and memory allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000466 seconds (1 allocation: 16 bytes)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "500220.6882968192"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time sum(x) # no compilation time after first run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more robust benchmarking, we use BenchmarkTools.jl package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 10000 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m264.284 μs\u001b[22m\u001b[39m … \u001b[35m701.111 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m295.739 μs               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m301.928 μs\u001b[22m\u001b[39m ± \u001b[32m 27.926 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▄\u001b[39m▅\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[34m▆\u001b[39m\u001b[39m▄\u001b[39m▄\u001b[32m▄\u001b[39m\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▁\u001b[39m▂\u001b[39m▄\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▃\n",
       "  264 μs\u001b[90m           Histogram: frequency by time\u001b[39m          412 μs \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm = @benchmark sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.295739"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_result[\"Julia builtin\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Julia, handwritten loop\n",
    "\n",
    "Let's also write a loop and benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 4177 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m1.133 ms\u001b[22m\u001b[39m … \u001b[35m 1.987 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m1.176 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m1.193 ms\u001b[22m\u001b[39m ± \u001b[32m65.523 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.00% ± 0.00%\n",
       "\n",
       "  \u001b[39m \u001b[39m▄\u001b[39m▆\u001b[39m▂\u001b[39m▁\u001b[39m \u001b[39m▃\u001b[39m█\u001b[34m▄\u001b[39m\u001b[39m▃\u001b[39m▁\u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m▆\u001b[39m\u001b[39m▄\u001b[39m▄\u001b[39m▂\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▂\u001b[39m▂\u001b[39m▂\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m▂\n",
       "  1.13 ms\u001b[90m        Histogram: frequency by time\u001b[39m        1.45 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m0 bytes\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m0\u001b[39m."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function jl_sum(A)\n",
    "    s = zero(eltype(A))\n",
    "    for a in A\n",
    "        s += a\n",
    "    end\n",
    "    s\n",
    "end\n",
    "\n",
    "bm = @benchmark jl_sum($x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.175818"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_result[\"Julia loop\"] = median(bm.times) / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: annotate the loop by [@simd](https://docs.julialang.org/en/v1/manual/performance-tips/#man-performance-annotations-1) and benchmark again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9-element Vector{Pair{Any, Any}}:\n",
       "  \"Julia builtin\" => 0.295739\n",
       "   \"Python numpy\" => 0.41202\n",
       "              \"C\" => 1.1608855\n",
       "     \"Julia loop\" => 1.175818\n",
       "         \"R Rcpp\" => 1.2082829999986444\n",
       "      \"R builtin\" => 2.4625275000014213\n",
       "         \"R loop\" => 13.011620000000335\n",
       " \"Python builtin\" => 74.757128\n",
       "    \"Python loop\" => 95.496408"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort(collect(benchmark_result), by = x -> x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `C`, `R builtin` are the baseline C performance (gold standard).\n",
    "\n",
    "* `Python builtin` and `Python loop` are 80-100 fold slower than C because the loop is interpreted.\n",
    "\n",
    "* `R loop` is about 30 folder slower than C and indicates the performance of JIT bytecode generated by its compiler package (turned on by default since R v3.4.0 (Apr 2017)). \n",
    "\n",
    "* `Julia loop` is close to C performance, because Julia code is JIT compiled.\n",
    "\n",
    "* `Julia builtin` and `Python numpy` are 3-4 folder faster than C because of SIMD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take home message for computational scientists\n",
    "\n",
    "- High-level language (R, Python, Matlab) programmers should be familiar with existing high-performance packages.  Don't reinvent wheels.  \n",
    "    - R: RcppEigen, tidyverse, ...   \n",
    "    - Python: numpy, scipy, ...  \n",
    "\n",
    "- In most research projects, looping is unavoidable. Then we need to use a low-level language.  \n",
    "    - R: Rcpp, ...  \n",
    "    - Python: Cython, ...  \n",
    "    \n",
    "- In this course, we use Julia, which seems to circumvent the two language problem. So we can spend more time on algorithms, not on juggling $\\ge 2$ languages.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "511.7391357421875px",
    "width": "251.7391357421875px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "640.4212036132812px",
    "left": "0px",
    "right": "1210.6114501953125px",
    "top": "109.57880401611328px",
    "width": "211.99728393554688px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
